name: Test AI Inference

on:
  push:
    branches: [feature/-]
  pull_request:
    branches: [main, devlelop]
  workflow_dispatch:
    

jobs:
  inference:
    permissions:
      models: read
    runs-on: ubuntu-latest
    steps:
      - name: Test Local Action
        id: inference
        uses: actions/ai-inference@v1
        with:
          prompt: "Hello, how are you?"
          model: "gpt-4o"
          endpoint: "https://api.rdsec.trendmicro.com/prod/aiendpoint/v1/"
          token: ${{ secrets.TM_API_KEY }}
          max-tokens: 1000

      - name: Print Output
        id: output
        run: echo "${{ steps.inference.outputs.response }}"

      - name: invoke atlassian-mcp
        env:
          CONFLUENCE_URL: ${{ secrets.CONFLUENCE_URL }}
          CONFLUENCE_USERNAME: ${{ secrets.CONFLUENCE_USERNAME }}
          CONFLUENCE_API_TOKEN: ${{ secrets.CONFLUENCE_API_TOKEN }}
          JIRA_URL: ${{ secrets.JIRA_URL }}
          JIRA_USERNAME: ${{ secrets.JIRA_USERNAME }}
          JIRA_API_TOKEN: ${{ secrets.JIRA_API_TOKEN }}
        run: |
          npm install -g mcp-remote
          mcp-remote https://mcp.atlassian.com/v1/sse 443

      
